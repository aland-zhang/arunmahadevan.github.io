# Default values for Livy.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

global: {}

strategy: {}
  # type: RollingUpdate
  # rollingUpdate:
  #   maxSurge: 0
  #   maxUnavailable: 1

image:
  repository: sasnouskikh/livy
  tag: 0.7.0-incubating-spark_2.4.2_2.11-hadoop_3.2.0
  pullPolicy: IfNotPresent

nameOverride: ""
fullnameOverride: ""

rbac:
  create: false

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

sparkServiceAccount:
  # Specifies whether a service account should be created
  create: true
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

service:
  type: ClusterIP
  port: 80
  additionalPorts: []
  #  - name: rpc10000
  #    port: 10000

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    #
    # nginx.ingress.kubernetes.io/auth-url: "https://$host/oauth2/auth"
    # nginx.ingress.kubernetes.io/auth-signin: "https://$host/oauth2/start?rd=$escaped_request_uri"
    # or
    # nginx.ingress.kubernetes.io/auth-type: basic
    # nginx.ingress.kubernetes.io/auth-secret: auth-secret
    # nginx.ingress.kubernetes.io/auth-realm: 'Authentication Required'
    #
    # nginx.ingress.kubernetes.io/rewrite-target: /$1
  path: /
  # path: /livy/?(.*)
  hosts:
  - livy.local
  tls: []
  # - secretName: livy-tls
  #   hosts:
  #   - livy.local

imagePullSecrets: []
# - name: image-pull-secret-name

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}
  # nodeAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     nodeSelectorTerms:
  #     - matchExpressions:
  #       - key: autoscale-retain
  #         operator: In
  #         values:
  #         - "true"

## Persist data to a persistent volume
persistence:
  enabled: false
  # subPath: ""

  ## If defined, will use the existing PVC and will not create a new one.
  # existingClaim: ""

  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  accessMode: ReadWriteOnce
  size: 20Gi
  annotations: {}

env:
  LIVY_LIVY_UI_BASE1PATH: {value: ""}
  LIVY_LIVY_SERVER_SESSION_STATE0RETAIN_SEC: {value: "12h"}
  LIVY_LIVY_SERVER_SESSION_MAX0CREATION: {value: "10"}
  LIVY_LIVY_SERVER_RECOVERY_MODE: {value: "recovery"}
  LIVY_LIVY_SERVER_RECOVERY_STATE0STORE: {value: "filesystem"}
  LIVY_LIVY_SERVER_RECOVERY_STATE0STORE_URL: {value: "file:///tmp/livy/store/state"}
  LIVY_LIVY_SERVER_RECOVERY_LOG0STORE: {value: "filesystem"}
  LIVY_LIVY_SERVER_RECOVERY_LOG0STORE_URL: {value: "file:///tmp/livy/store/log"}
  LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE: {value: "sasnouskikh/livy-spark:0.7.0-incubating-spark_2.4.2_2.11-hadoop_3.2.0"}
  LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE_PULL1POLICY: {value: "IfNotPresent"}
  LIVY_SPARK_EVENT1LOG_ENABLED: {value: "true"}
  LIVY_SPARK_EVENT1LOG_DIR: {value: "file:///tmp/history-server"}
  LIVY_SPARK_KUBERNETES_DRIVER_ANNOTATION_CREATED0BY: {value: "livy"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_ANNOTATION_CREATED0BY: {value: "livy"}
  LIVY_SPARK_KUBERNETES_DRIVER_LABEL_NAME: {value: "driver"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_LABEL_NAME: {value: "executor"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_REQUEST_CORES: {value: "0.1"}
  LIVY_SPARK_EXECUTOR_MEMORY: {value: "512m"}
  LIVY_SPARK_DRIVER_MEMORY: {value: "512m"}
  LIVY_SPARK_DRIVER_CORES: {value: "0.1"}
  LIVY_SPARK_EXECUTOR_INSTANCES: {value: "1"}
  LIVY_SPARK_KUBERNETES_DRIVER_VOLUMES_PERSISTENT1VOLUME1CLAIM_CHECKPOINTPVC_MOUNT_PATH: {value: "/tmp/history-server"}
  LIVY_SPARK_KUBERNETES_DRIVER_VOLUMES_PERSISTENT1VOLUME1CLAIM_CHECKPOINTPVC_MOUNT_READ1ONLY: {value: "false"}
  LIVY_SPARK_KUBERNETES_DRIVER_VOLUMES_PERSISTENT1VOLUME1CLAIM_CHECKPOINTPVC_OPTIONS_CLAIM1NAME: {value: "task-pv-claim"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_VOLUMES_PERSISTENT1VOLUME1CLAIM_CHECKPOINTPVC_MOUNT_PATH: {value: "/tmp/history-server"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_VOLUMES_PERSISTENT1VOLUME1CLAIM_CHECKPOINTPVC_MOUNT_READ1ONLY: {value: "false"}
  LIVY_SPARK_KUBERNETES_EXECUTOR_VOLUMES_PERSISTENT1VOLUME1CLAIM_CHECKPOINTPVC_OPTIONS_CLAIM1NAME: {value: "task-pv-claim"}
  # LIVY_SPARK_KUBERNETES_CONTAINER_IMAGE_PULL1SECRETS: {value: ""}
  LIVY_LIVY_UI_HISTORY0SERVER0URL: {value: "http://spark-history-server.example.com"}
  LIVY_LIVY_SERVER_KUBERNETES_INGRESS_CREATE: {value: "true"}
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_PROTOCOL: {value: "http"}
  LIVY_LIVY_SERVER_KUBERNETES_INGRESS_HOST: {value: "cluster.example.com"}
  #
  #LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1ANNOTATIONS: {value: "kubernetes.io/tls-acme=true;nginx.ingress.kubernetes.io/auth-url=https://$host/oauth2/auth;nginx.ingress.kubernetes.io/auth-signin=https://$host/oauth2/start?rd=$escaped_request_uri"}
  # or
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1ANNOTATIONS: {value: "kubernetes.io/tls-acme=true;nginx.ingress.kubernetes.io/auth-type=basic;nginx.ingress.kubernetes.io/auth-secret=secret-namespace/auth-secret;nginx.ingress.kubernetes.io/auth-realm=Authentication Required"}
  #
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_TLS_SECRET1NAME: {value: "spark-cluster-tls"}
  # LIVY_LIVY_SERVER_KUBERNETES_INGRESS_ADDITIONAL1CONF1SNIPPET: {value: ""}
  # LIVY_ENV_VAR_FROM_CONFIG_MAP:
  #   valueFrom:
  #     configMapKeyRef:
  #       name: myconfig
  #       key: config.key
  # LIVY_ENV_VAR_FROM_SECRET:
  #   valueFrom:
  #     secretKeyRef:
  #       name: mysecret
  #       key: secret.key

envFrom: []
# - configMapRef:
#     name: env-configmap
# - secretRef:
#     name: env-secrets

livyConf: {}
#  fromConfigMap: "livy-conf-config-map"
#  fromSecret: "livy-conf-secret"

sparkDefaultsConf: {}
# fromConfigMap: "spark-defaults-conf-config-map"
# fromSecret: "spark-defaults-conf-secret"

livyClientConf: {}
# fromConfigMap: "livy-client-conf-config-map"
# fromSecret: "livy-client-conf-secret"
